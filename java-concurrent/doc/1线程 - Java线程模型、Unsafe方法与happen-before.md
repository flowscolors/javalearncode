## 线程模型 OS、Java级别

Java线程模型就是一对一模型，也即一个线程会映射成一个真正的OS线程。Go的线程模型GMP就是多对多关系，goroutine的高效某种程度来源于此。

### JMM Java内存模型
首先我们由一个例子来认识Java内存模型。如果有一个线程要为变量aVariable赋值：
aVariable = 3；
内存模型需要解决这个问题:“在什么条件下，读取aVariable的线程会看到这个值为3”。听起来很简单，但如果缺少同步，会有很多因素导致线程无法立即甚至永远看不到另一个线程操作的结果。
编译器、JIT、JVM、OS、CPU都可能有重排序等机制。而随着多核CPU的普及，JVM需要有一种机制来完成同步操作，从而协调多个线程间的共享数据。

JMM规定了JVM必须遵循的一组最小保证，这组保证规定了对变量的写入操作在何时将对其他线程可见。并且JMM在设计时就在可预测性和程序的易于开发性间进行了权衡。
当然之所以能做这些，是因为各自CPU都定义了各自的内存屏障指令，当需要共享数据时，可以使用这些指令实现额外的存储协调保证，Java为了调用多平台的内存屏障，自己定义了8个原子语句。


书接上文，计算机内存模型是一种解决多线程场景下的一个主存操作规范，既然是规范，那么不同的编程语言都可以遵循这种操作规范，在多线程场景下访问主存保证原子性、可见性、有序性。
Java内存模型(Java Memory Model，JMM)即是Java语言对这个操作规范的遵循，JMM规定了所有的变量都存储在主存（Heap）中，每个线程都有自己的工作区（Stack），
线程将使用到的变量从主存中复制一份到自己的工作区，线程对变量的所有操作(读取、赋值等)都必须在工作区(也即栈帧中的局部变量表)，不同的线程也无法直接访问对方工作区，线程之间的消息传递都需要通过主存来完成。可以把这里主存类比成计算机内存模型中的主存，工作区类比成计算机内存模型中的高速缓存。

可以说Java运行时模型的堆区、栈区、方法区就是建立在JMM基础上的。堆区存共享变量，栈区的局部变量表load共享变量、修改并回写回堆区(这部分回写实际使用的是OS的共享内存实现)。而OS的共享内存并不能保证顺序性和有序性，于是Java就要去解决了。

而我们知道JMM其实是工作主存中的，Java内存模型中的工作区也是主存中的一部分，所以可以这样说Java内存模型解决的是内存一致性问题(主存和主存)而计算机内存模型解决的是缓存一致性问题(CPU高速缓存和主存)，这两个模型类似，但是作用域不一样，Java内存模型保证的是主存和主存之间的原子性、可见性、有序性，而计算机内存模型保证的是CPU高速缓存和主存之间的原子性、可见性、有序性。
因为CPU只能解决缓存的问题，不能解决内存的问题，于是JMM Java内存模型，实际上是对Java多线程的线程一致性问题的解决，可以说是必然之路。

Java线程的所有操作都是在工作区进行的，那么工作区和主存之间的变量交互如下图。OS的共享内存使用。  
![](https://cdn.jsdelivr.net/gh/flowscolors/resources-backup@main/img_bed/Java内存模型交互图.JPG)
Java通过8种原子操作完成工作区内存和主存的交互，注意该规则已弃用，JSR-133中已放弃该描述，但JMM没有变。

lock：作用于主存，把变量标识为线程独占状态。
unlock：作用于主存，解除变量的独占状态。
read：作用于主存，把一个变量的值通过主存传输到线程的工作区内存。
load：作用于工作区内存，把read操作传过来的变量值储存到工作区内存的变量副本中。
use：作用于工作内存，把工作区内存的变量副本传给执行引擎。
assign：作用于工作区内存，把从执行引擎传过来的值赋值给工作区内存的变量副本。
store：作用于工作区内存，把工作区内存的变量副本传给主存。
write：作用于主存，把store操作传过来的值赋值给主存变量。


这8个操作每个操作都是原子性的，但是几个操作连着一起就不是原子性了！

> Java为什么要做JMM，而不是L1 cache这种模型？
> 答：Java 作为高级语言，屏蔽了 L1 缓存、L2 缓存、L3 缓存，也就是多层缓存的这些底层细节，用 JMM 定义了一套读写数据的规范。我们不再需要关心 L1 缓存、L2 缓存、L3 缓存等多层缓存的问题，我们只需要关心 JMM 抽象出来的主内存和工作内存的概念。

通过该模型，每个线程只能直接接触工作内存，无法直接操作主内存，而工作内存中保存的是主内存的共享变量的副本，主内存与共享内存的通信由JMM控制。  
JMM 有以下规定：

（1）所有的变量都存储在主内存中，同时每个线程拥有自己独立的工作内存，而工作内存中的变量的内容是主内存中该变量的拷贝；

（2）线程不能直接读 / 写主内存中的变量，但可以操作自己工作内存中的变量，然后再同步到主内存中，这样，其他线程就可以看到本次修改；

（3） 主内存是由多个线程所共享的，但线程间不共享各自的工作内存，如果线程间需要通信，则必须借助主内存中转来完成。

jvm屏障规范，以下这4种内存屏障是jvm的实现，具体记录在jsr-133，并非OS的内存屏障。/src/hotspot/share/runtime/orderAccess.hpp 
具有以下类型的屏障为jvm的规范，具体的实现由jvm实现，jvm通过硬件级别的屏障实现，需要根据具体的CPU进行实现

* LoadLoad屏障 对于这样的语句Load1;LoadLoad;Load2，
在Load2及后续读取操作尧都区的数据被访问前，要保证Load1要读取的数据被读取完毕。

* StoreStroe屏障 对于这样的语句Store1；StoreStore;Store2，
在Store2及后续写入操作前，保证Store1的写入操作对其它处理器课件。

* LoadStore屏障 对于这样的语句Load1;LoadStore;Store2,
在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。

* StoreLoad屏障 对于这样的语句Store1;StoreLoad;Load2，
在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。

StoreLoad Barriers同时具备其他三个屏障的效果，因此也称之为全能屏障（mfence），是目前大多数处理器所支持的；但是相对其他屏障，该屏障的开销相对昂贵。

### OS线程模型



### 线程同步机制
多线程的意思就是多个线程同时工作，那么多线程之间如何协同合作，这也就是我们需要解决的线程通信、线程同步问题

线程通信：线程通信指线程之间以何种机制来交换消息，线程之间的通信机制有两种：共享内存和消息传递。共享内存即线程通过对共享变量的读写而达到隐式通信，消息传递即线程通过发送消息给对方显示的进行通信。
线程同步：线程同步指不同线程对同一个资源进行操作时候线程应该以什么顺序去操作，线程同步依赖于线程通信，以共享内存方式进行线程通信的线程同步是显式的，以消息传递方式进行线程通信的线程同步是隐式的。

## Java程序与unsafe方法

Java对于操作系统底层接口的调用都是基于Unsafe(sun.misc.Unsafe)类实现，但是Java的跨平台性限制了Java不能和操作系统耦合，所以Java并没有在Unsafe类直接实现CAS的操作，而是通过JDI(Java Native Interface) 本地调用C/C++语言来实现CAS操作的。

![](https://cdn.jsdelivr.net/gh/flowscolors/resources-backup@main/img_bed/java_unsafe.jpg)


## happens-before 规则
Happens-before 关系是用来描述和可见性相关问题的：如果第一个操作 happens-before 第二个操作（也可以描述为，第一个操作和第二个操作之间满足 happens-before 关系），那么我们就说第一个操作对于第二个操作一定是可见的，也就是第二个操作在执行时就一定能保证看见第一个操作执行的结果。  
如果分别有操作 x 和操作 y，用 hb(x, y) 来表示 x happens-before y。  

（1）单线程规则： 在一个单独的线程中，按照程序代码的顺序，先执行的操作 happen-before 后执行的操作。也就是说，如果操作 x 和操作 y 是同一个线程内的两个操作，并且在代码里 x 先于 y 出现，那么有 hb(x, y)。  

（2）锁操作规则（synchronized 和 Lock 接口等）： 如果操作 A 是解锁，而操作 B 是对同一个锁的加锁，那么 hb(A, B) 。  

（3）volatile 变量规则： 对一个 volatile 变量的写操作 happen-before 后面对该变量的读操作。

（4）线程启动规则： Thread 对象的 start 方法 happen-before 此线程 run 方法中的每一个操作。

（5）线程 join 规则：假设线程 A 通过调用 threadB.start() 启动了一个新线程 B，然后调用 threadB.join() ，那么线程 A 将一直等待到线程 B 的 run 方法结束（不考虑中断等特殊情况），然后 join 方法才返回。  

（6）中断规则： 对线程 interrupt 方法的调用 happens-before 检测该线程的中断事件。

（7）并发工具类的规则：
> 线程安全的并发容器（如 HashTable）在 get 某个值时一定能看到在此之前发生的 put 等存入操作的结果。
>信号量（Semaphore）它会释放许可证，也会获取许可证。这里的释放许可证的操作 happens-before 获取许可证的操作.
>Future：Future 有一个 get 方法，可以用来获取任务的结果。那么，当 Future 的 get 方法得到结果的时候，一定可以看到之前任务中所有操作的结果，也就是说 Future 任务中的所有操作 happens-before Future 的 get 操作。
>线程池：要想利用线程池，就需要往里面提交任务（Runnable 或者 Callable），这里面也有一个 happens-before 关系的规则，那就是提交任务的操作 happens-before 任务的执行。

## happen-before 规则实现
happen-before实际的实现是由JVM、JIT、OS、CPU共同实现的，而具体实现其实依赖OS提供的内存屏障功能。
简单来说默认情况下Java多线程的执行逻辑是基于共享内存把堆区变量在栈帧的临时变量表中修改，因此会有并发问题。而在happen-before中使用单线程、volatile、join时，JVM会给你加上loadload、loadstore、storestore等内存屏障来保证顺序性。

参考文档：
http://gee.cs.oswego.edu/dl/jmm/cookbook.html


## 内存屏障实现
不同服务器对内存屏障的实现不同，x86并没有实现全部的内存屏障。
 /arch/x86/include/asm/barrier.h
“读屏障” 对一个对象引用进行读操作之前或之后附加执行的逻辑，相当于为引用读取挂上的一小段钩子代码。
lfence：load | 在lfence指令前的读操作当必须在lfence指令后的读操作前完成。   lfence指令实现了Load Barrier，相当于LoadLoad Barriers。  

“写屏障” 对一个对象引用进行写操作（即引用赋值）之前或之后附加执行的逻辑，相当于为引用赋值挂上的一小段钩子代码。  
sfence：store | 在sfence指令前的写操作当必须在sfence指令后的写操作前完成。  sfence指令实现了Store Barrier，相当于StoreStore Barriers。  
例：HotSpot通过写屏障来维护卡表。写屏障就是在将引用赋值写入内存之前，先做一步mark card——即将出现跨代引用的内存块对应的卡页置为dirty。

"读写屏障"  mfence：mix | 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。   mfence指令实现了Full Barrier，相当于StoreLoad Barriers。  

Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。
用来修饰当前指令操作的内存只能由当前CPU使用，若指令不操作内存仍然由用，因为这个修饰会让指令操作本身原子化，而且自带Full Barrior效果；还有指令比如IO操作的指令、exch等原子交换的指令，任何带有lock前缀的指令以及CPUID等指令都有内存屏障的作用。


参考文档： 
https://sbexr.rabexc.org/latest/sources/55/b70e0cd908b742.html