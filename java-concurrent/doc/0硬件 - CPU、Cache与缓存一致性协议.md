## 1.CPU架构

### 多核CPU
多核CPU或者叫多处理器（multiprocessor）包括多个硬件处理器，每个都能执行一个顺序程序。当讨论多处理器架构的时候，基本的时间单位是指令周期（cycle）：即处理器提取和执行一条指令需要的时间。

当单个CPU主频超过一定范围后，CPU成本和散热成了很大的问题，主频很难突破10GHz。

为了获得更快的计算速度和更好的性能，芯片设计者决定绕过主频，采用人海战术，在一块CPU中增加多个核心（Core）。

一个核心是一个可以运行指令的独立单元，它包含了ALU和寄存器，并配备L1和L2 Cache。多个核心共享L3 Cache。  

### 多核CPU互联方法
多核情况下如何进行计算任务，目前常见的三种服务器基本互联结构：

SMP(symmetric multiprocessing，对称多处理) UMA
NUMA(nonuniform memory access，非一致内存访问)

SMP 指多个 CPU 对称工作，无主次或从属关系。各 CPU 共享相同的物理内存。每个 CPU 访问内存中的任何地址所需时间是相同的，因此 SMP 也被称为一致存储器访问结构（即 UMA：Uniform Memory Access）。一般 SMP 架构中，CPU 和内存之间存在高速缓存。并且，处理器和主存都有用来负责发送和监听总线上广播信息的总线控制单元（bus controller）。这种结构最为容易实现，但是随着处理器的增多，总线并不能扩展导致总线终将过载。

在 NUMA 系统结构中，与 SMP 相反，一系列节点通过点对点网络互相连接，有点像一个小型的局域网，每个节点包含若干个处理器和本地内存。一个节点的本地存储对于其他节点也是可以访问的，当然，访问自己的本地内存要快于访问其他节点的内存。网络比总线复杂，需要更加复杂的协议，但是带来了扩展性。但是实际上NUMA也存在自己的一些问题，可能导致高性能场景下的切换问题。

异构架构，即芯片上有不同类型的内核，P、E类型。可以将高性能的计算任务分配到对应CPU执行。

从程序员的角度看，无论底层是 SMP 还是 NUMA，互连线都是有限的资源。写代码的时候，要考虑这一点避免使用过多的总线Bus资源。所以后面讨论到占用总线资源的操作，无论在SMP还是NUMA上都应该尽量避免。  

### CPU功能：  
每个CPU的计算过程：
取指 -> 解码 -> 执行 -> 写回  
前两部分为前端，大致流程为*处理器通过给内存发送一个包含要读取的地址的信息，来获取内存上对应地址的值。*这部分相当于是提供给真正计算的弹药，所以要上cache尽快读取到。  

后两部分为后端，大致流程为*ALU计算单元，进行并行计算，顺序或乱序执行完计算任务；处理器将结果发送给内存，这里会发送要写入的值，和要写入的地址数据写回后内存回复一个确认消息*。  

周而复始，循环进行上述操作。  

为了提升前端的操作性能，于是引入了高速缓存Cache，并且有了三级Cache机制。  
并且由于大部分程序表现出较高的局部性、于是高速缓存操作的不是一个字，而是一个缓存行，因此当我们需要保证操作字的时候需要考虑这一点。  
前端如此重要的原因在于后端实在太快了，计算和读取写入的时间差距太大。  
可以说，计算机的速度瓶颈，已经变成了超高速的CPU运算速度（纳秒级别）与落后的数据读取速度（百纳秒）之间的矛盾。



### 对于计算机各类操作的基本耗时比较

实际计算需要1ns，分支预测大概需要5ns，而访问内存需要100ns，于是写出对Cache友好的程序对于极致追求性能的程序来说至关重要。

对同样读1MB数据，内存花费250，000ns，SSD是1，000，000ns，磁盘是20，000，000ns（20ms）。内存是SSD的4倍，磁盘的80倍。

而网络与磁盘的速度比较，如果两台主机比较接近，则时间主要在封装报文，两边发送、接受的IO耗时；而如果两台主机比较远，则时间主要在两地的光纤上了，就如果CA到Netherlands常年需要150ms。以磁盘一次寻道10ms为基准，如果同数据中心时延大概在0.01~0.5ms左右，同城机房如果10公里，大概需要1~10ms，异地机房大概需要10~20ms，跨国机房大概需要100+ms.

![](https://cdn.jsdelivr.net/gh/flowscolors/resources-backup@main/img_bed/2020年的计算机操作耗时.JPG)

### CPU指令集
CPU为不同的计算任务设计了不同的指令集，来解决诸如边缘计算、机器学习、常规计算等任务。
而最常用的指令集就是x86，当然汇编指令和x86指令集其实是有区别的。
x86指令集：  
* 数据传输指令 MOV、PUSH、POP、XCHG、CMPXCHG、IN、OUT
* 算数运算指令 ADD、SUB、MUL、DIV
* 逻辑运算指令 AND、OR、NOT、TEST
* 串指令      MOVS
* 程序转移指令 JMP、LOOP
* 惟    



### 前端 - 多级高速缓存：  
现代处理器中一般不止一级缓存，而是多级缓存，从离处理器最近到最远分别是 L1 Cache，L2 Cache 和 L3 Cache：

L1 Cache 通常和处理器位于同一个芯片，离处理器最近，访问仅需要 1~3 个指令周期  
L2 Cache 通常和处理器位于同一个芯片，处于边缓位置，访问需要通过更远的铜线，甚至更多的电路，从而增加了延时，一般在 8 ~ 11 个指令周期左右  
L3 Cache L1/L2 为每个处理器私有的，这样导致对于很多相同的数据，也只能每个处理器独有的缓存各保存一份。所以需要考虑引入一个所有处理器共用的缓存，这就是 L3 缓存。L3 缓存的材质以及布线都和 L1/L2 不同，需要更长的时间访问，一般在 20 ~ 25 个指令周期左右





### 前端 - 缓存替换策略：

高速缓存内存有限，在同一时刻只有一部分内存单元被放置在高速缓存中，因此我们需要缓存替换策略。如果替换策略可以替换任何缓存行，则该高速缓存是**全相联(fully associative)的。相反，如果只能替换一个特定的缓存行，他就是直接映射(direct mapped)的。如果取其折中，即允许使用一组大小为 k 的集合中任一缓存行来替换，则称为k 级组相联(k-way set associative)**的。

### 前端 - 缓存一致性协议

当一个处理器访问另一个处理器已经装载入高速缓存的主存地址的时候，就会发生共享（sharing，或者称为争用 contention）。需要考虑缓存一致性的问题，因为如果一个处理器要更新共享的缓存行，则另一个处理器的副本需要作废以免读取到过期的值。

intel的 MESI 缓存一致性协议，MESI协议保证每个CPU高速缓存中的变量都是一致的。它的核心思想是，当CPU写数据时候，如果发现操作的变量是共享变量(即其他CPU上也存在该变量)，就会发出信号通知其他CPU将它高速缓存中缓存这个变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己高速缓存中缓存该变量的缓存行为无效状态，那么它就会从主存中重新读取。  
缓存行存在以下四种状态：
Modified：缓存行被修改，最终一定会被写回入主存，在此之前其他处理器不能再缓存这个缓存行。
Exclusive：缓存行还未被修改，但是其他的处理器不能将这个缓存行载入缓存
Shared：缓存行未被修改，其他处理器可以加载这个缓存行到缓存
Invalid：缓存行中没有有意义的数据

比如：  
TASLock 的每次 LOCKED.compareAndSet(this, false, true) 的时候，都会产生修改信号，占用总线带宽。while循环时会导致大量总线占用。
TTASLock 的 LOCKED.get(this) 仅仅是一次本地自旋。仅检查处理器自己的数据和内存数据有没有被别人改过，基于嗅探机制从Cache读，不占用总线，性能会好很多。

> 缓存一致性协议有很多种 除了最常见的MESI协议，还有Write Through、Write Once、Firefly等协议

可视化链接：
https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/
https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm

### 后端 - ALU
这里ALU计算单元实际也是并行执行，所以可能会乱序。这就会带来指令重排的问题。
因为是流水线式的输入，则处理器(CPU)为了提高效率可能会对输入的代码进行乱序执行。

当然，CPU设计者已经考虑到这些问题，所以缓存一致性问题、指令重排问题，CPU基于计算机内存模型提供了一定的解决。一定程度上保证了多线程场景下的原子性、可见性、有序性，


## 2.进程与线程
前面的知识都是硬件层面，而线程和进程则是操作系统控制这些硬件而创造的软件概念，  
这些都属于一种软件抽象，当然这层抽象也有不同等级，操作系统等级和程序语言等级。

进程(Process) 进程，具有独立的计算资源，如内存空间。

线程(Thread) 线程，是进程的一个子集。

一个进程默认启动一个线程，也可以启动多个线程，多个线程共享进程的资源。

在多核架构出现之前，CPU在特定时刻只能执行某个程序，无法并行。
因为CPU的处理速度是纳秒级的，在单核时代，为了同时处理多项任务，只能以多线程，CPU切换不同的线程任务

而多核时代到来之后，就可以把一个任务拆分到不同CPU上执行，提供程序执行效率。  

### 上下文切换
无论是单核时代的，多进程之间切换，还是多核时代的线程切换，都是CPU的上下文切换。  
上下文切换（context switch）指的是处理器可以执行一个线程一段时间之后去执行另一个线程。处理器可以因为各种原因撤销一个线程或者从调度中删除该线程：

* 线程发出了一个内存请求，而该请求需要一段时间才能完成
* 线程已经运行了足够长的时间，该让别的线程执行了。
PS： 当线程被从调度中删除时，他可能重新在另一个处理器上执行。

### 多线程就一定比单线程快吗？
答案是不一定，因为多线程存在单线程没有的问题
* 缓存一致性问题
* 指令重排问题（单线程也存在）
* 上下文切换：线程从运行状态切换到阻塞状态或者等待状态的时候需要将线程的运行状态保存，线程从阻塞状态或者等待状态切换到运行状态的时候需要加载线程上次运行的状态。线程的运行状态从保存到再加载就是一次上下文切换，而上下文切换的开销是非常大的，而我们知道CPU给每个线程分配的时间片很短，通常是几十毫秒(ms)，那么线程的切换就会很频繁。
* 死锁：死锁的一般场景是，线程A和线程B都在互相等待对方释放锁，死锁会造成系统不可用。
* 资源限制的挑战：资源限制指计算机硬件资源或软件资源限制了多线程的运行速度，例如某个资源的下载速度是1Mb/s，资源的服务器带宽只有2Mb/s，那么开10个线程下载资源并不会将下载速度提升到10Mb/s。



参考文档：  
https://blog.csdn.net/The_Time_Runner/article/details/103348137
https://zhuanlan.zhihu.com/p/418887488
https://zhuanlan.zhihu.com/p/387117470
https://mp.weixin.qq.com/s/qrdFkdUzLLdEzoy1RIplHA
https://www.cnblogs.com/lsgxeva/p/8948153.html
